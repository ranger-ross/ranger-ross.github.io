<!doctype html><html lang=en><head><meta charset=UTF-8><meta content="default-src 'self';font-src 'self' data:;img-src 'self' https://* data:;media-src 'self';style-src 'self';frame-src player.vimeo.com https://www.youtube-nocookie.com;connect-src 'self';script-src 'self' 'self'" http-equiv=Content-Security-Policy><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://ranger-ross.github.io name=base><title>
ranger-ross • AGI is not guaranteed</title><link title="ranger-ross - Atom Feed" href=https://ranger-ross.github.io/atom.xml rel=alternate type=application/atom+xml><link href="https://ranger-ross.github.io/custom_subset.css?h=0b9535a28bc3d5bf2321" rel=stylesheet><link href="https://ranger-ross.github.io/main.css?h=295fef347cdd0e4ad21f" rel=stylesheet><link href="https://ranger-ross.github.io/skins/blue.css?h=a4dc1e94d3f5759784d2" rel=stylesheet><meta content="light dark" name=color-scheme><meta content="Thoughts on the state of AI progress" name=description><meta content="Thoughts on the state of AI progress" property=og:description><meta content="AGI is not guaranteed" property=og:title><meta content=article property=og:type><meta content=en_GB property=og:locale><meta content=https://ranger-ross.github.io/blog/agi-is-not-guaranteed/ property=og:url><meta content=ranger-ross property=og:site_name><noscript><link href=https://ranger-ross.github.io/no_js.css rel=stylesheet></noscript><script src=https://ranger-ross.github.io/js/initializeTheme.min.js></script><script defer src=https://ranger-ross.github.io/js/themeSwitcher.min.js></script><script src="https://ranger-ross.github.io/js/searchElasticlunr.min.js?h=3626c0ef99daa745b31e" defer></script><body><header><nav class=navbar><div class=nav-title><a class=home-title href=https://ranger-ross.github.io>ranger-ross</a></div><div class=nav-navs><ul><li><a class="nav-links no-hover-padding" href=https://ranger-ross.github.io/blog/>blog </a><li><a class="nav-links no-hover-padding" href=https://ranger-ross.github.io/projects/>projects </a><li class=menu-icons-container><ul class=menu-icons-group><li class="js menu-icon"><div aria-label="Click or press $SHORTCUT to open search" class="search-icon interactive-icon" title="Click or press $SHORTCUT to open search" id=search-button role=button tabindex=0><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/></svg></div><li class="theme-switcher-wrapper js"><div aria-label="Toggle dark mode" title="Toggle dark/light mode" aria-pressed=false class=theme-switcher role=button tabindex=0></div><div aria-label="Reset mode to default" class="theme-resetter arrow" title="Reset mode to default" aria-hidden=true role=button tabindex=0></div></ul></ul></div></nav></header><div class=content><main><article><h1 class=article-title>AGI is not guaranteed</h1><ul class=meta><li>9th Aug 2025<li title="1109 words"><span aria-hidden=true class=separator>•</span>6 min read</ul><section class=body><p>I have seen a lot of bold claims about AI lately around its potential implications for the workforce. For example, the Anthropic CEO said that “in 3 to 6 months, AI will be writing 90% of code.” <sup class=footnote-reference id=fr-1-1><a href=#fn-1>1</a></sup> Recently at work, a coworker said “Coding will become like art, where humans will only do it for pleasure” implying that AI will be so much more productive than humans. These conversations have led me to reflect on the state of AI and its future.<h2 id=where-we-are-today>Where we are today</h2><p>To think about the future we need to understand where we are currently. It’s been nearly 3 years since the initial release of ChatGPT at the time of writing. Since then we have seen a lot of improvement to the underlying models. Improved context windows, better weights through better training, new protocols that allow them to interact with external systems, etc. The latest frontier is agentic models with a heavy focus on coding.<p>The current focus of many large tech firms is operationalizing AI agents to accelerate development and reduce the engineering headcount needed to deliver new features. With the state of current AI agents, they are capable of producing usable code in small and medium sized codebases. However, even in medium sized codebases these agents run into context window limitations and need to be used in short bursts or use some workarounds like “summarizing” context to make it smaller. Agents can be useful tools, but they appear to be just that, <strong>tools</strong>. Even with the state of the art models, they still need to be operated by a human that has some idea of what they are doing. At least in the short term the idea of a completely autonomous agent is not anywhere near practical.<h2 id=looking-to-the-future>Looking to the future</h2><p>While the current focus of many companies is agents, many AI companies have their eyes on artificial general intelligence or AGI. There are many definitions of AGI, but I am going to define it as: A machine or software that can match peak human performance at any task. In other words, anything you can do, it can do better. Many of the leaders in the AI space and government institutions believe that we are on a crash course to achieving AGI.<p>This is concerning to me as there is nothing guaranteeing AGI will happen or even exists. There are important questions we need to answer first:<ol><li>Is AGI even possible?<li>Is the current approach to AI a local minima?<li>How will we know if AGI is achieved?</ol><p>The concept of AGI can certainly exist in a perfect world. However, we do not live in a perfect world. There are many equations in physics that have theoretical solutions but realistically will never happen due to environmental constraints. I believe the bar for AGI is not completely out of reach as it only needs to surpass humans, which are also imperfect. But we still need to take in the environmental constraints like energy production, training data, etc.<p>Current AI models are notoriously resource intensive. Given that we do not even have a known end point for achieving AGI we also do not know how much energy is required to achieve AGI. For all we know the energy required to operate AGI could exceed the amount of available energy in our solar system. If this is the case, AGI would not be practically possible in my lifetime. I tend to believe it should be possible with much less energy, but the fact of the matter is we do not know.<p>This leads me to ask is the current approach to AI even optimal in the first place? LLMs and RAGs have given us a great leap forward on AI progress but there is a potential that we are approaching a local minimum. In the short term, we see great improvements to AI capabilities but in the long term we hit limits to the algorithms and hardware. I tend to believe this is the case. Our models are very impressive from previous AI capabilities but we are starting to see diminishing returns on training and model/context size. If we want to see more large leaps it will require going backwards (likely for years) to develop a new approach to model reality.<p><img alt src=/img/agi.jpg><p>Finally we have no way of knowing if we have achieved AGI. The best we have now are AI benchmarks and anecdotal evidence. AI benchmarks are a useful tool but it is unclear if scores relate to real world performance. We also see AI companies prioritizing these benchmarks while neglecting areas that are not tested by benchmarks.<p>Given the state of AI capability measurement, I suspect we will see an AI company (or government) prematurely declare AGI has been achieved. There are many incentives to do so, so I would not find this as shocking to see in the next 5 years.<h2 id=is-all-lost>Is all lost?</h2><p>I tend to view the current AI hype cycle as a bubble no different than the dotcom bubble in the 1990s. All of the large AI companies are bleeding money and investors will only wait so long to see a return. The hype behind AI has not been what it can do, but what it can do now but what it will do in the future. Eventually, these companies will need to provide some path to sustainability and we have not seen any sign of that.<p>However, this does not mean that all AI tools are useless. In the dotcom bubble of the 1990s, many companies failed but the actually useful products like Google survived and thrived. But for us to get there we will need to live through the AI bubble.<p>We see a lot of companies feeling pressured to adopt AI. While there are legitimate use cases for AI, many companies are jumping on AI to please investors or simply out of <a href=https://wikipedia.org/wiki/FOMO>FOMO</a>. This is unfortunate for consumers of software but unlikely to change in the near future.<p>Once the VC money eventually dries up and hype has died down, I am optimistic that trend of putting AI into everything will stop and we will see a more conservative thoughtful use of AI in applications. AI unlocks use cases that were previously not possible but it is not a silver bullet that solves all problems and we are not guaranteed to see AGI anytime in the near future.<hr><section class=footnotes><ol class=footnotes-list><li id=fn-1><p><a href=https://www.businessinsider.com/anthropic-ceo-ai-90-percent-code-3-to-6-months-2025-3>https://www.businessinsider.com/anthropic-ceo-ai-90-percent-code-3-to-6-months-2025-3</a> <a href=#fr-1-1>↩</a></p></ol></section></section></article></main><div id=button-container><div id=toc-floating-container><input class=toggle id=toc-toggle type=checkbox><label class=overlay for=toc-toggle></label><label title="Toggle Table of Contents" class=button for=toc-toggle id=toc-button><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M414.82-193.094q-18.044 0-30.497-12.32-12.453-12.319-12.453-30.036t12.453-30.086q12.453-12.37 30.497-12.37h392.767q17.237 0 29.927 12.487 12.69 12.486 12.69 30.203 0 17.716-12.69 29.919t-29.927 12.203H414.82Zm0-244.833q-18.044 0-30.497-12.487Q371.87-462.9 371.87-480.45t12.453-29.92q12.453-12.369 30.497-12.369h392.767q17.237 0 29.927 12.511 12.69 12.512 12.69 29.845 0 17.716-12.69 30.086-12.69 12.37-29.927 12.37H414.82Zm0-245.167q-18.044 0-30.497-12.32t-12.453-30.037q0-17.716 12.453-30.086 12.453-12.369 30.497-12.369h392.767q17.237 0 29.927 12.486 12.69 12.487 12.69 30.203 0 17.717-12.69 29.92-12.69 12.203-29.927 12.203H414.82ZM189.379-156.681q-32.652 0-55.878-22.829t-23.226-55.731q0-32.549 23.15-55.647 23.151-23.097 55.95-23.097 32.799 0 55.313 23.484 22.515 23.484 22.515 56.246 0 32.212-22.861 54.893-22.861 22.681-54.963 22.681Zm0-245.167q-32.652 0-55.878-23.134-23.226-23.135-23.226-55.623 0-32.487 23.467-55.517t56.12-23.03q32.102 0 54.721 23.288 22.62 23.288 22.62 55.775 0 32.488-22.861 55.364-22.861 22.877-54.963 22.877Zm-.82-244.833q-32.224 0-55.254-23.288-23.03-23.289-23.03-55.623 0-32.333 23.271-55.364 23.272-23.03 55.495-23.03 32.224 0 55.193 23.288 22.969 23.289 22.969 55.622 0 32.334-23.21 55.364-23.21 23.031-55.434 23.031Z"/></svg></label><div class=toc-content><div class=toc-container><ul><li><a href=https://ranger-ross.github.io/blog/agi-is-not-guaranteed/#where-we-are-today>Where we are today</a><li><a href=https://ranger-ross.github.io/blog/agi-is-not-guaranteed/#looking-to-the-future>Looking to the future</a><li><a href=https://ranger-ross.github.io/blog/agi-is-not-guaranteed/#is-all-lost>Is all lost?</a></ul></div></div></div><a title="Go to the top of the page" class=no-hover-padding href=# id=top-button> <svg viewbox="0 0 20 20" fill=currentColor><path d="M3.293 9.707a1 1 0 010-1.414l6-6a1 1 0 011.414 0l6 6a1 1 0 01-1.414 1.414L11 5.414V17a1 1 0 11-2 0V5.414L4.707 9.707a1 1 0 01-1.414 0z"/></svg> </a></div><span class=hidden id=copy-success> Copied! </span><span class=hidden id=copy-init> Copy code to clipboard </span><script defer src=https://ranger-ross.github.io/js/copyCodeToClipboard.min.js></script></div><footer><section><nav class="socials nav-navs"><ul><li><a class="nav-links no-hover-padding social" href=https://ranger-ross.github.io/atom.xml> <img alt=feed loading=lazy src=https://ranger-ross.github.io/social_icons/rss.svg title=feed> </a><li><a class="nav-links no-hover-padding social" rel=" me" href=https://github.com/ranger-ross/> <img alt=github loading=lazy src=https://ranger-ross.github.io/social_icons/github.svg title=github> </a><li><a class="nav-links no-hover-padding social" rel=" me" href=https://www.linkedin.com/in/ross-sullivan-a17568135/> <img alt=linkedin loading=lazy src=https://ranger-ross.github.io/social_icons/linkedin.svg title=linkedin> </a></ul></nav><nav class=nav-navs></nav><div class=credits><small> </small></div></section><div class="search-modal js" aria-labelledby=modalTitle id=searchModal role=dialog><h1 class=visually-hidden id=modalTitle>Search</h1><div id=modal-content><div id=searchBar><div aria-hidden=true class=search-icon><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/></svg></div><input aria-controls=results-container aria-expanded=false autocomplete=off id=searchInput placeholder=Search… role=combobox spellcheck=false><div class="close-icon interactive-icon" title="Clear search" id=clear-search role=button tabindex=0><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/></svg></div></div><div id=results-container><div id=results-info><span id=zero_results> No results</span><span id=one_results> $NUMBER result</span><span id=many_results> $NUMBER results</span><span id=two_results> $NUMBER results</span><span id=few_results> $NUMBER results</span></div><div id=results role=listbox></div></div></div></div></footer>